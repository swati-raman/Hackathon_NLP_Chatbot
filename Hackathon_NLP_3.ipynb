{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk \n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.stem import wordnet # to perform lemmitization\n",
    "from sklearn.feature_extraction.text import CountVectorizer # to perform bow\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # to perform tfidf\n",
    "from nltk import pos_tag # for parts of speech\n",
    "from sklearn.metrics import pairwise_distances # to perfrom cosine similarity\n",
    "from nltk import word_tokenize # to create tokens\n",
    "from nltk.corpus import stopwords # for stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Answer</th>\n",
       "      <th>Question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yes. It's absolutely beautiful today.</td>\n",
       "      <td>The weather is great isn't it?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yes, i like that one, too.</td>\n",
       "      <td>that one. the one that's all black.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>it's really nice.</td>\n",
       "      <td>i got it from macy's.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>at 8:00 p.m.</td>\n",
       "      <td>when does it start?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nothing, except my favorite color is blue.</td>\n",
       "      <td>what's the matter with green eyes?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I have read just about everything in Project ...</td>\n",
       "      <td>have you ever read a book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a fancy name for applied computer science in ...</td>\n",
       "      <td>what is bioinformatics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sure, the changing rooms are over there.</td>\n",
       "      <td>Can I try it on?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I want it taken from my checking account.</td>\n",
       "      <td>Which account are you making this withdrawal f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>and you get to play with a lot of dogs.</td>\n",
       "      <td>that's the truth.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>A game with tall players.</td>\n",
       "      <td>WHAT IS BASKETBALL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>and then we can go to my home.</td>\n",
       "      <td>we can watch my dvd.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>i will talk to your father about that.</td>\n",
       "      <td>i saw dad wipe his nose on his sleeve yesterday.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Thank you so much.</td>\n",
       "      <td>I can cancel it for you right now.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>it's your girlfriend's fault. she should have ...</td>\n",
       "      <td>i'm sure everything will be okay in a day or two.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>what have you been doing?</td>\n",
       "      <td>i've actually been busy lately.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>it was a great game.</td>\n",
       "      <td>i wish i was free that night. i'm kind of mad ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>I am fine</td>\n",
       "      <td>How are you doing today?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>i'm not sure yet.</td>\n",
       "      <td>i'm going to the movies with a friend. how abo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>they are bites.</td>\n",
       "      <td>what are they?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Answer  \\\n",
       "0               Yes. It's absolutely beautiful today.   \n",
       "1                          yes, i like that one, too.   \n",
       "2                                   it's really nice.   \n",
       "3                                        at 8:00 p.m.   \n",
       "4          nothing, except my favorite color is blue.   \n",
       "5    I have read just about everything in Project ...   \n",
       "6    a fancy name for applied computer science in ...   \n",
       "7            Sure, the changing rooms are over there.   \n",
       "8           I want it taken from my checking account.   \n",
       "9             and you get to play with a lot of dogs.   \n",
       "10                          A game with tall players.   \n",
       "11                     and then we can go to my home.   \n",
       "12             i will talk to your father about that.   \n",
       "13                                 Thank you so much.   \n",
       "14  it's your girlfriend's fault. she should have ...   \n",
       "15                          what have you been doing?   \n",
       "16                               it was a great game.   \n",
       "17                                          I am fine   \n",
       "18                                  i'm not sure yet.   \n",
       "19                                    they are bites.   \n",
       "\n",
       "                                             Question  \n",
       "0                      The weather is great isn't it?  \n",
       "1                 that one. the one that's all black.  \n",
       "2                               i got it from macy's.  \n",
       "3                                 when does it start?  \n",
       "4                  what's the matter with green eyes?  \n",
       "5                           have you ever read a book  \n",
       "6                              what is bioinformatics  \n",
       "7                                    Can I try it on?  \n",
       "8   Which account are you making this withdrawal f...  \n",
       "9                                   that's the truth.  \n",
       "10                                 WHAT IS BASKETBALL  \n",
       "11                               we can watch my dvd.  \n",
       "12   i saw dad wipe his nose on his sleeve yesterday.  \n",
       "13                 I can cancel it for you right now.  \n",
       "14  i'm sure everything will be okay in a day or two.  \n",
       "15                    i've actually been busy lately.  \n",
       "16  i wish i was free that night. i'm kind of mad ...  \n",
       "17                           How are you doing today?  \n",
       "18  i'm going to the movies with a friend. how abo...  \n",
       "19                                     what are they?  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('/Users/swatiraman/Downloads/NLP Hackathon/Hackathon File/TrainData.txt',sep='\\t')\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5495, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5495 entries, 0 to 5494\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Answer    5495 non-null   object\n",
      " 1   Question  5495 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 86.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_characters(text, remove_digits=False):\n",
    "    pattern = r'[^a-zA-z0-9\\s]' if not remove_digits else r'[^a-zA-z\\s]'\n",
    "    text = re.sub(pattern, '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/swatiraman/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'lemmatize' from 'gensim.utils' (/opt/anaconda3/lib/python3.8/site-packages/gensim/utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-297b9fb47c36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlemmatize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'lemmatize' from 'gensim.utils' (/opt/anaconda3/lib/python3.8/site-packages/gensim/utils.py)"
     ]
    }
   ],
   "source": [
    "from gensim.utils import lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that performs text normalization steps\n",
    "\n",
    "def text_normalization(text):\n",
    "    text=str(text).lower() # text to lower case\n",
    "    spl_char_text=re.sub(r'[^ a-z]','',text) # removing special characters\n",
    "    tokens=nltk.word_tokenize(spl_char_text) # word tokenizing\n",
    "    lema=wordnet.WordNetLemmatizer() # intializing lemmatization\n",
    "    tags_list=pos_tag(tokens,tagset=None) # parts of speech\n",
    "    lema_words=[]   # empty list \n",
    "    for token,pos_token in tags_list:\n",
    "        if pos_token.startswith('V'):  # Verb\n",
    "            pos_val='v'\n",
    "        elif pos_token.startswith('J'): # Adjective\n",
    "            pos_val='a'\n",
    "        elif pos_token.startswith('R'): # Adverb\n",
    "            pos_val='r'\n",
    "        else:\n",
    "            pos_val='n' # Noun\n",
    "        lema_token=lema.lemmatize(token,pos_val) # performing lemmatization\n",
    "        lema_words.append(lema_token) # appending the lemmatized token into a list\n",
    "    \n",
    "    return \" \".join(lema_words) # returns the lemmatized tokens as a sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lemmatized_text']=df['Question'].apply(text_normalization) # applying the fuction to the dataset to get clean text\n",
    "df.tail(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using tf-idf\n",
    "\n",
    "tfidf=TfidfVectorizer() # intializing tf-id \n",
    "x_tfidf=tfidf.fit_transform(df['Question']).toarray() # transforming the data into array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns all the unique word from data with a score of that word\n",
    "\n",
    "df_tfidf=pd.DataFrame(x_tfidf,columns=tfidf.get_feature_names()) \n",
    "df_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function that returns response to query using tf-idf\n",
    "\n",
    "def chat_tfidf(text):\n",
    "    lemma=text_normalization(text) # calling the function to perform text normalization\n",
    "    tf=tfidf.transform([lemma]).toarray() # applying tf-idf\n",
    "    cos=cosine_similarity(df_tfidf,tf) # applying cosine similarity\n",
    "    index_value=cos.argmax() # getting index value \n",
    "    return df['Answer'].loc[index_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('/Users/swatiraman/Downloads/NLP Hackathon/Hackathon File/TestData.csv')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = []\n",
    "for text in test_df['Question']:\n",
    "    #print(text,':',chat_tfidf(text))\n",
    "    answer.append(chat_tfidf(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['answer']=answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_df.drop('Answer',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[['I.D.','answer']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[['I.D.','answer']].to_csv('SwatiRaman_3.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#data = pd.read_csv('qa.csv')\n",
    "data=pd.read_csv('/Users/swatiraman/Downloads/NLP Hackathon/Hackathon File/TrainData.txt',sep='\\t')\n",
    "# this function is used to get printable results\n",
    "def getResults(questions, fn):\n",
    "    def getResult(q):\n",
    "        answer, score, prediction = fn(q)\n",
    "        return [q, prediction, answer, score]\n",
    "    return pd.DataFrame(list(map(getResult, questions)), columns=[\"Q\", \"Prediction\", \"A\", \"Score\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('/Users/swatiraman/Downloads/NLP Hackathon/Hackathon File/TestData.csv')\n",
    "final_data = pd.DataFrame(columns=[\"Q\", \"Prediction\", \"A\", \"Score\"])\n",
    "from Levenshtein import ratio\n",
    "def getApproximateAnswer(q):\n",
    "    max_score = 0\n",
    "    answer = \"\"\n",
    "    prediction = \"\"\n",
    "    for idx, row in data.iterrows():\n",
    "        score = ratio(row[\"Question\"], q)\n",
    "        if score >= 0.9: # I'm sure, stop here\n",
    "            return row[\"Answer\"], score, row[\"Question\"]\n",
    "        elif score > max_score: # I'm unsure, continue\n",
    "            max_score = score\n",
    "            answer = row[\"Answer\"]\n",
    "            prediction = row[\"Question\"]\n",
    "    if max_score > 0.3: # threshold is lowered\n",
    "        return answer, max_score, prediction\n",
    "    return \"Sorry, I didn't get you.\", max_score, prediction\n",
    "final_data = getResults(test_data['Question'], getApproximateAnswer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.to_csv('final_data.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
